Notes by Allen Cee



## Lecture 01 机器学习简介



### 机器学习算法 Machine learning algorithms

**常见算法**

1. Supervised learning 监督学习
2. Unsupervised learning 无监督学习

**其他**

1. Reinforcement learning 强化学习
2. Recommender systems 推荐系统

### 监督学习 Supervised Learning

1. 监督学习：已知部分数据集，给出算法，预测新数据
   1. 回归问题 Regression Problem：监督学习的一种，预测连续值 continuous values（如房价、股价）[Fig 01-01]
   2. 分类问题 Classification Problem：监督学习的一种，预测离散值输出 discrete valued ouput（如肿瘤性质） [Fig 01-02] & [Fig 01-03]

* 学习算法能够处理无穷多的属性（支持向量机 Support Vector）

### 无监督学习 Unsupervised Learning

1. 无监督学习：数据集中所有数据是一样的、没有属性，通过算法，找到某种结构（如谷歌新闻分类、特定基因判定）【个人感觉和主成分分析、因子正则化比较像】
   1. 聚类 Cluster：无监督学习的一种，具体定义还不清楚，将无属性数据通过算法分出不同属性的类（如社交网络分析、市场分割、星体分类等）[Fig 01-04]

* 鸡尾酒宴会问题 Cocktail Party Problem：不同音源如何区分；有鸡尾酒算法
* Octave常用来开发程序原型，因为内置了很多学习算法，如`svd()`奇艺值分解



## Lecture 02 模型基础



### 模型表示 Model Representation

**Eg 02-01: Housing Prices** [Fig 02-01]

* 训练集 Training Set：监督学习中已知的数据集 [Fig 02-02]

**机器学习中的常见表示** [Fig 02-03]

### 代价函数/成本函数 Cost Function

* 确定模型参数的依据是「使假设函数预测的$h(x)$与$y$尽可能接近」，所用的函数称为代价函数 $J(\theta_0, \theta_1)$ [Fig 02-04]

* 通常用平方误差代价函数Squared Error Function，其他函数也可，平方误差代价函数对大多数回归问题效果都不错
* 区分假设函数和代价函数：一个是$x\to y​$的映射，一个是$\theta \to J​$的映射；图为1个参数代价函数选取最佳参数值的直观展示 [Fig 02-05] & [Fig 02-06] & [Fig 02-07] & [Fig 02-08]
* 两个参数的代价函数会形成弓形曲面，竖向值代表代价函数的值，投影到地面形成轮廓图Contour Plot/Contour Figure【类似等高线图】[Fig 02-10]

### 梯度下降算法 Gradient Descent

* 梯度下降算法：用于使代价函数$J$最小，也用于机器学习其他领域，非常常用

**梯度下降算法的思想** [Fig 02-11]

1. 选择代价函数$J$中$\theta$的初始值，一般都设为$0$
2. 不断改变$\theta$的值，直至代价函数最小

* 就像下山一样，像下降最快的方向前进，通过偏微分判断$\theta_i$的改变方向 [Fig 02-12]
* 梯度下降算法可能出现多个局部最优解，而初始值可能非常接近
* $:=$是赋值符号 [Fig 02-13]
* $\alpha$是对应的学习速率，即$\theta_i$下降的步长
* 注意：需要同时更新$\theta_0$和$\theta_1$的值
* $\alpha$过大可能导致结果无法收敛，甚至发散 [Fig 02-14]
* 因为导数会越来越小，所以$\alpha$保持不变也会使结果收敛（步长趋近于$0$，达到局部最优点）

### 线性回归 Linear Regression

**线性回归代价函数的偏微分求解** [Fig 02-15] & [Fig 02-16]

* 梯度下降算法对应的代价函数需要是弓形曲线/曲面，即凸函数Convex Function
* 批处理梯度下降算法 Batch Gradient Descent：一次性用所有训练集中的样本计算最佳参数，即$\sum$的范围是$1$到$m$【意思应该是有时候可能处理训练集的子集】



## Lecture 03 线性代数



### 矩阵和向量 Matrices and Vectors

**矩阵的行、列、维度** [Fig 03-01]

**矩阵的元素：下标先行后列** [Fig 03-02]

**向量：一列/一行矩阵【一般用列】** [Fig 03-03]

* 数学（线性代数中）索引通常从1开始，机器学习中通常从0开始，具体情况具体讨论
* 大写字母通常表示矩阵，小写字母表示数字

### 矩阵与标量的乘法

* 维度相同才能加减

### 矩阵与向量的乘法

* 向量的维度和矩阵的列数相同，向量由上至下和矩阵由左至右相乘 [Fig 03-04] & [Fig 03-05]
* 原始数据和假设函数一起计算预测值时，用矩阵乘向量更简单、更快 [Fig 03-06]

### 矩阵与矩阵的乘法

* 分别用第一个矩阵乘第二个矩阵按列拆分的向量，再合并 [Fig 03-07] & [Fig 03-08]
* 原始数据和多个假设函数一起计算预测值时，可以用矩阵乘矩阵【为调整参数比较收益提供了思路】 [Fig 03-09]

### 矩阵乘法的性质

* 不具备交换律 not commutative
* 单位矩阵 Identity Matrix：用$I$表示，行列相同，左上角到右下角是1，其余是0；满足$A\times I=I\times A=A$【注意两个$I$不是同一个，前者是$A$的列数，后者是$A$的行数】 [Fig 03-10]

### 逆运算和转置 Inverse and Transpose

* 逆矩阵的概念对应实数的倒数
* 只有行列相同的矩阵才可能有逆矩阵，即方阵；但不是所有方阵都有逆矩阵；0没有倒数，显然所有元素是零的矩阵没有逆矩阵；逆矩阵不存在的矩阵称为奇异矩阵 singular 或退化矩阵 degenerate
* 直观上可以将没有逆矩阵的矩阵想象为非常接近于0
* $A$的转置矩阵$A^T$是将原来的行从上至下依次变为从左至右的列，即$A_{ij}=A^T_{ji}$ [Fig 03-11] 



## Lecture 04 线性回归



### 多元线性回归 Multivariate Linear Regression

* 记法：$x^{(i)}_j$表示第$i$个样本中的第$j$个变量 [Fig 04-01]
* 将一个样本的多个变量写为一个向量（竖向，$x_0=1$），对应参数也写为向量，则$h_\theta(x)=\theta^Tx$ [Fig 04-02] 
* 将模型参数看做一个向量，同样的，代价函数的作用也是$n+1$维的向量 [Fig 04-03] & [Fig 04-04]

### 特征缩放 Feature Scaling

* 特征缩放：使多个特征处于相近的范围；使用梯度下降算法的时候会更快，因为更加均匀 [Fig 04-05]
* 一般缩放到$-1 \sim 1$的范围，如果是$-\frac{1}{3} \sim \frac{1}{3}$或者$-3\sim 3$，也可以接受 [Fig 04-06]
* 均值归一化 Mean Normalization：缩放特征的时候，分子减去均值，以使缩放后的值均值接近0，分母为最大值减最小值或者是标准差等等 [Fig 04-07]

### 学习速率 Learning Rate

* 通过绘出迭代步数和代价曲线的图形可以判断出迭代是否进行正确，曲线需要是减函数，进行到接近平行于$x$轴时即可以认为已经收敛了；选择阈值（自动收敛测试 Automatically Convergence Test）很难适应所有情况，最好都画图感知 [Fig 04-08]
* 不同问题需要收敛的迭代步数差距可能很大（也和选取的初始值有关系）
* 如果迭代是增函数或呈现周期性，通常需要选择更小的学习速率
* 一般选择$0.001$，$0.003$，$0.01$，$0.03$，$0.1$，$0.3$，$1$等等，隔三倍

### 特征选择 Features

* 充分考虑特征的含义，如房价特征选择面积而不是长和宽【多因子选股也要充分考虑因子背后的含义，计量上的因子乘积项也起了这样的作用，不过有时候意义很难理解】 [Fig 04-09]

### 多项式回归 Polynomial Regression

* 多项式：一个变量，多个次项【文中举了housing Price和size的关系的例子，房价在不同面积区间的表达可能很难用一个多项式函数去拟合，即使用全部数据拟合，预测效果也很差；无法仅通过size决定housing Price，size对housing price的影响应该控制其他变量不变，即不能使用现实数据，应该使用实验数据，得到的不是房价结果而是房价的实验结果比较结果，因此这里得到复杂的多项式没有意义，不应该将其他变量承载的解释力转移到函数关系式上】
* 可以将不同次项当作不同的变量进行多元线性回归处理

### 正规方程 Normal Equation

* 标准方程：用于求解参数$\theta$【应该通常是用于线性回归】
* 对于每个样本按行排列的矩阵$X$（即矩阵$X$由样本向量$x^{(i)}$的转置$(x^{(i)})^T$按行构成），结果向量$y$，参数向量$\theta$，有$\theta = (X^TX)^{-1}X^Ty$ [Fig 04-10]
* 标准方程法不需要特征缩放，也不需要梯度下降的迭代和学习速率选择；梯度下降法在特征数量很大（上百万）的时候也适用，标准方程法因为要求$X^TX$及求其逆矩阵（逆矩阵的计算量约为维度的三次方），如果特征数量太大矩阵维度会过大；一般特征数量上百或上千会选择标准方程法，上万会用梯度下降法；还有其他学习算法如分类算法和逻辑回归，不能使用标准方程法，只能使用梯度下降法

* 在正规方程中，若$X^TX$具有不可逆性noninvertibility，octave的pinv()函数同样可以计算它的逆矩阵，即可求它的伪逆，inv()函数则不行（inv()中有数值计算的概念）

1. 若$X^TX$不可逆，通常有两种情况
   1. 有多余的特征redundant features，参数间线性相关linearly dependent
   2. 特征数量太多，通常是特征数量$n\geq m$样本量（小数据样本得到大量参数值可以通过正则化regularization）



## Lecture 05 Octave



### 基本操作 Basic Operation

* 不等于`~=`，异或`xor(1, 0)`
* 抑制打印输出：句末加`;`；打印和类型化输出：`disp(sprintf('%0.10f', pi))`
* 矩阵生成：`A = [1 2; 3 4; 5 6]`，分号隔开不同行；同一行不同列可用空格隔开，也可以用逗号；步长列表生成：`v = 1:0.1:2`，步长为0.1；生成元素同一的矩阵：`C = 9*ones(2, 3); W = zeros(1, 3);`；元素随机的矩阵：`R = rand(3, 3)`，数值介于0-1之间；高斯随机/正态分布随机：`N = randn(3, 3)`；单位矩阵：`I = eye(4)`；魔方阵/幻方：`A = magic(3)`，每行每列每条对角线加和相同
* 直方图/柱状图：`w = -6 + sqrt(10)*(randn(1, 10000)); hist(w); hist(w, 100)`；注意正常显示的条数比较少
* 矩阵维度：`size(A); size(A, 1); size(A, 2)`，依次返回行数和列数；向量维度：`length(v)`
* 加载文件：`load file.dat`或者`load(file.dat)`；保存文件：`save file.dat v;`，二进制形式；`save file.txt v -ascii;`文本格式
* 查看工作空间中所有变量：`who; whos`，后者还会显示size和数据类型class；清除变量：`clear var; clear`，后者清除所有变量
* 切片：`v(2:5); A(1:6);`，行/列向量均可切片，矩阵按列由左至右；切片结果会平面化为行向量；`A(:)`是切片为列向量；查看/赋值元素：`A(3, 2); A(2, :); A(:, 3); A([1, 3], :)`，返回元素/行/列/某几个元素或行列；也可进行赋值
* 基础运算：`A*B; A.*B; A.^2; 1 ./ A`，第二组是标量点乘，第三组对标量进行运算，第四组是点除【如果实数对矩阵每个元素做除法一定要用点除，但加减乘都可以直接进行，也满足交换律，`A/2`也可以】；`log(v); abs(A); -v;  `；`sum(A); prod(A); floor(A); ceil(A);`求每列所有元素之和/积以及向下向上取整，相当于`sum(A, 1)`，可以用`sum(A, 2)`对每行操作
* 矩阵操作：`A‘`转置；`pinv(A)`逆矩阵；`[value, index] = max(v)`求最大值及其索引，可以只有value，注意`max(A)`是对每一列求最大值，返回行向量，可以用`max(A, [], 2)`来求每行最大值，也可以用`max(max(A)) or max(A(:))`来求矩阵中所有元素的最大值；`max(A, B)`，按每个元素比较得到最大的元素组成的新矩阵；`A<5`对每个元素进行`bool`化，满足为1否则为0，`[r, c] = find(A<5)`求索引，矩阵按列，返回列向量；`flipup(A); flipud(A)`向上向下翻转

### 绘制数据 Plotting Data

* 折线图：`plot(v1, v2)`，行/列向量均可；`plot(v1, v2, 'r')`，红色
* 同一张画布画多个图像，画下一个前用`hold on;`
* 添加标签等：`xlabel('time'); ylabel(value)； legend('line1', 'line2'); title('plot 01')`
* 保存图像：`print -dpng 'plot.png'`
* 关闭图像：`close`【只有close能够正常关闭，目前的电脑不能点红叉或快捷键，会出问题orz】
* 定义画布：`figure(1); plot(...)`
* 定义子图：`subplot(1, 2, 1);`，分别是行、列、第几个子图【pyplot应该是一样的，即按照顺序进行读取，所以在splt上画/处理与plt直接处理有时候是一样的】
* 刻度变换：`axis(0.5 1 -1 1)`，先后分别是x轴和y轴
* 热度图：`imagesc(A)`，用不同颜色显示不同数字；`imagesc(A), colorbar, colormap gray;`，显示颜色条，用灰度图

### 控制语法与函数

* for循环：

  ```octave
  for i=1:10,
    v(i) = 2^i;
    if i == 2,
      break;
    elseif i == 1,
      continue;
    end;
  end;
  ```

* while大致如此，continue和break照常；区别在于不用冒号用逗号，以及控制语句结束加`end;`

* 函数：`myfunction.m`

  ```octave
  function y = squareThisNumber(x) % function y 的含义是返回一个值y, 同时有一个参数x
  y = x^2
  ```

  ```octave
  function [y1, y2] = squareAndCubeThisNumber(x)
  y1 = x^2
  y2 = x^3
  ```

  调用：`[a, b] = squareAndCubeThisNumber(5)`

### 向量化 Vectorization

* 未向量化即for循环，向量化即将加和转化为向量的积 [Fig 05-01] & [Fig 05-02]



## Lecture 06 逻辑回归 Logistic Regression



### 分类 Classification

* 标记为0的类为负类negtive class；标记为1的类为正类positive class；一般红叉表示正类，蓝圈表示负类
* 分为二元分类问题binary classification problems和多元分类问题multiclass classification problems [Fig 06-01]
* 为什么不用线性回归：对异常点的处理差；回产生大于1和小于0的值，在解释上比较无意义 [Fig 06-02]

### 逻辑回归的假设函数 Hypothesis Representation

* 类似线性回归假设函数$h(x) = \theta^Tx$，稍作改变为$h(x) = g(\theta^T x)$，其中$g(z)=\frac{1}{1+e^{-z}}$即S型函数sigmoid function/logistic function [Fig 06-03]
* 这里的假设函数给出的是给定$x$和$\theta$的概率，正类

### 分类的决策边界 Decision Boundary

* 即线性函数$z = \theta^T x$；当$z\geq0$的时候，$g(z)\geq 0.5$，$h(x)$取1，分为正类

### 逻辑回归的代价函数 Cost Function

* 相比线性回归的代价函数，逻辑回归的代价函数保留了样本数量的均值化，即$J(\theta)=\frac{1}{m}cost\ function$，其中$cost(h, y)=\frac{1}{2}(h-y)^2$，但在逻辑回归里面这样会产生非凸函数non-convex function，不利于梯度下降 [Fig 06-04]
* 所做的改变是对假设函数取对数，消减指数及倒数的影响，得到逻辑回归代价函数$cost(h, y)=\begin{cases}  -\log(h(x)) \quad if \ y = 1\\ -\log(1-h(x)) \quad if\ y=0 \end{cases}$ [Fig 06-05]
* 逻辑回归的代价函数通过统计学的极大似然法the principle of maximum likelihood得到

**逻辑回归代价函数的直观理解【通过y->h(x)->cost(h, y)的连结，会出现当h接近y的时候cost接近0，背离的时候cost接近无穷大的结果】** [Fig 06-06] & [Fig 06-07] & [Fig 06-08]

* 代价函数可以优化为$cost(h, y)=-y\log(h(x))-(1-y)(1-h(x))$ [Fig 06-09] 

### 逻辑回归中梯度下降的应用

* 对代价函数求偏导，迭代即可 [Fig 06-10]
* 逻辑回归梯度下降的迭代公式和线性回归很相似，只是假设函数的内涵不同 [Fig 06-11]
* 注意应用使梯度下降结果收敛的方法，以及通过特征缩放提高梯度下降效率

### 高级优化 Advanced Optimization

* 重要的是代价函数的式子和偏导数的求解式，解决这两部分后除梯度下降还有很多优化算法pptimization algorithm可以使用，如共轭梯度法Conjugate Gradient、变尺度法BFGS和限制变尺度法L-BFGS，这些算法通常无需选择学习速率、计算速度更快，同时也更复杂 [Fig 06-12]

* 建议直接使用软件库，无需理解高级算法内涵；使用库也要比较不同库的区别，找到一个实现表现好的库

* octave实现：

  ```octave
  function [jVal, gradient] = costFunction(theta)
  jVal = ... % cost function
  gradient = zeros(n+1, 1) % vector of theta
  gradient(i) = ...
  ```

  然后使用高级优化算法`fminunc()`，该函数会自动选择学习算法（如果选择梯度下降也会自动选择学习速率）；注意该函数的theta至少是二维向量 [Fig 06-13]

### 多元分类：一对多算法 Multi-class Classification: One-VS-All Algorithm

* 一对多算法：通过创建伪训练集，将多元分类问题转化为多个二元分类问题，具体样本的分类结果取可信度最大的一个【即分为哪一种类的概率最大，就认为样本属于哪一种类别】 [Fig 06-14] & [Fig 06-15]



## Lecture 07 正则化 Regularization



### 过拟合 Overfitting

* 欠拟合Underfitting/高偏差High Bias：算法没有很好地拟合训练样本
* 过拟合Overfitting/高方差High Variance：没有足够的训练样本去拟合过多的变量，导致拟合效果过好；会导致无法泛化generalize到新样本中 [Fig 07-01] & [Fig 07-02]
* 泛化Generalize：假设模型能应用到新样本中的能力
* 绘制曲线可以判断是否过拟合，但变量多时不再适用

**处理过拟合的方法**

1. 减少变量数量
   1. 人工选择保留的变量
   2. 使用模型选择算法，自动判断哪些变量需要舍弃；问题是舍弃一部分特征变量也舍弃了相关信息
2. 正则化Regularization
   1. 保留所有特征，但是减少参数theta的数量级；保证了每一个变量都对预测结果产生一点影响 [Fig 07-03]

### 正则化的代价函数

* 正则化：在代价函数中添加惩罚项$\lambda\sum_{j=1}^{n}\theta_j^2$；当所有参数都很小的时候，假设会更简单，函数更光滑，更不容易发生过拟合；惩罚项就是正则化项 [Fig 07-04]
* 一般来说不惩罚$\theta_0$
* $\lambda$是正则化参数，用以平衡代价函数和参数过拟合风险（保持假设形式简单）
* 正则化参数不能过大，否则会使其他所有参数尽可能趋近于0，导致假设函数为$h(x)=\theta_0$ 【不惩罚$\theta_0$可能是使最终预测结果不趋近于$h(x)=0$而是直线$h(x)=\theta_0$】 [Fig 07-05] 

### 正则化线性回归 Regularized Linear Regression

* 在梯度下降递归偏导数中加上正则化项 [Fig 07-06]
* 正规方程中同样加上正则化项 [Fig 07-07]
* 只要正则化参数是大于零的，正规方程需要求逆矩阵的部分即使$m\leq n$样本数小于变量数，也是可逆的 [Fig 07-08]

### 正则化逻辑回归 Regularized Logistic Regression

* 同样在代价函数中加上正则化项 [Fig 07-09]
* 在梯度下降的递归函数加上正则化项的偏导数（和线性回归的方程类似）
* octave更新相应递归方程即可 [Fig 07-10]



## 神经网络 Neural Networks



### 非线性假设 Non-linear Hypotheses

* 神经网络是更强大的非线性分类器，处理变量太多的分类问题【对逻辑回归来说，变量太多会产生更多的交叉项和高次项，不利于处理】 [Fig 08-01]

### 神经元和大脑 Neurons and the Brain

* 神经重接实验表明，大脑对不同信号（触觉、听觉、视觉）的处理有统一的算法

### 神经网络模型 Neural Networks Model

* 神经元的处理是接收输入信号-计算-输出信号，然后传给下一个神经元 [Fig 08-02]
* 神经网络模型将神经元模拟成一个逻辑单元Logistic Unit，即对输入参数进行逻辑回归；输入参数中一般会出现$x_0$（但不一定在图中写出），即偏置单元Bias Unit或偏置神经元Bias Neuron [Fig 08-03]
* 神经网络中的S型函数Sigmoid Function/逻辑斯蒂函数Logistic Function被叫做激励函数Activation Function，参数theta有时被称为权重Weights
* 神经网络分为输入层、隐藏层（可以不止一个）和输出层；称为隐藏层只是因为在监督学习中，输入层和输出层的值都可见，只有隐藏层不可见 [Fig 08-04]

**神经网络中的常见表示（激励函数的值和权重矩阵等）【a表示activation，既是前一层的输出值，也是后一层的输入值；即每一层theta的行数为变量数+1，列数为下一层的单元个数】** [Fig 08-05]

### 前向传播 Forward Propagation

* 前向传播：用向量化的方法通过初始输入值依层计算激励 [Fig 08-06]
* 神经网络相当于多层的逻辑回归 [Fig 08-07]
* （神经网络的）架构 Architecture：神经元相连接的方式 [Fig 08-08]

**Eg 08-01: AND Funcion** [Fig 08-09]

**Eg 08-02: OR Function** [Fig 08-10]

**Eg 08-03: Negation Function** [Fig 08-11]

**Eg 08-04: XOR/XNOR Function** [Fig 08-12] & [Fig 08-13]

### 多元分类 Multiclass Classification

* 建立有多个输出单元的神经网络，最终结果为只有一个元素为1的向量（而非1234） [Fig 08-14]



## Lecture 09 反向传播算法 Backpropagation Algorithm



### 神经网络的代价函数 Cost Function

**神经网络中的常见表示（层数、每层单元数等）** [Fig 09-01]

* 神经网络的代价函数相当于将逻辑回归的代价函数泛化，即对所有输出层输出单元的假设函数值与真实值的偏差加和，加上所有层所有参数/权重的正则化项（不包括偏置单元，就像逻辑回归中也不对$\theta_0$进行正则化一样） [Fig 09-02]

### 反向传播算法 Backpropagation Algorithm

* 通过前向传播算法，可以用输入值计算所有激励值和输出值 [Fig 09-03]
* 反向传播的过程：通过$\delta$实现，delta代表某一单元的误差，实际上是代价函数对前一层某单元的偏导，这个偏导类似梯度下降中的偏导，最终通过递归会使得整个代价函数的取值减小；反向传播算法将这一误差从输出层向前传递了，最终可以求得每层的代价函数对参数/权重的偏导，即前一层的输入乘上下一层的误差（不含正则项）【文章《[知乎张磊：BP 神经网络 —— 逆向传播的艺术][https://zhuanlan.zhihu.com/p/36711903]》指出，实际上这是代价函数求偏导的一个过程，即；也就是说，这是逻辑回归的代价函数求偏导的特殊结果，对线性回归的代价函数并不能得到$\delta^{L}=h(x)-y$】 [Fig 09-04]
* 最后，通过每一层代价函数对前一层参数的偏导，来更新前一层的$\Delta$，用$\Delta$和正则项组成总的代价函数 [Fig 09-05]

* 前向传播的直观理解：$x\ or\ a\xrightarrow{\theta} z\xrightarrow{g(sigmoid\ function)}a\ or\ h$ [Fig 09-06]
* 后向传播的直观理解：误差$\delta$从后往前传播，$\delta$的含义是$\frac{\partial }{\partial z}Cost$，即前一层单元的$z$对最终代价函数的影响，也就对应了对权值做多少改变会如何影响中间激励值最终影响，最终影响神经网络输出
* 偏差单元怎么计算取决于神经网络算法如何实现，一般计算出其delta值但忽略 [Fig 09-07] & [Fig 09-08]

### 展开参数 Unrolling Parameters

* `fminunc(@costFunction, initialTheta, options)`函数的`initialTheta`和`costFunction`的返回值返回的`gradient`都是n+1维的向量，而神经网络提供的$\Theta^{(1)}$和$D^{(1)}$等都是矩阵（后者是梯度矩阵），故需要把矩阵展开为向量 [Fig 09-09]
* 展开方式为`thetaVec = [Theta1(:); Theta2(:); Theta(3)]; DVec = [D1(:); D2(:); D3(:)];`，也可以对新向量进行矩阵还原`Theta2 = reshape(thetaVec(111:220), 10, 11);`  [Fig 09-10]

**算法步骤** [Fig 09-11]

1. 展开初始参数传入`initialTheta`

2. 实现代价函数

   ```octave
   function [jVal, gradientVec] = costFunction(thetaVec)
   % 从thetaVec中获得三个Theta
   % 用前向传播/后向传播计算D和J(Theta)
   % 展开D得到gradientVec
   ```

### 梯度检测 Gradient Checking

* 因为神经网络比较复杂，反向传播过程中可能出现很多小错误；即是代价函数在梯度下降过程中看上去每次迭代都在减小，但最后得到的代价函数可能还是会比没有错误的要高
* 用导数的定义得到代价函数导数的估计，检验其是否和D近似 [Fig 09-12] & [Fig 09-13]
* `gradApprox`的计算量非常大，所以正式运行神经网络算法前需要关闭梯度检测的程序 [Fig 09-14]

### 随机初始化 Random Initialization

* 不能将参数初始化为0，因为这会导致第二层的激励值均相等，同时相应的误差也想等，最后更新的参数也是相等的 [Fig 09-15]
* 一般随机初始化为$[-\epsilon, \epsilon]$区间 [Fig 09-16]

### 神经网络总结

1. 建立框架Architecture：神经元之间的连接方式
   1. 由输入的特征数量决定输入单元数量
   2. 由分类问题中需要区分的类别数量决定输出单元数量
   3. 默认用单隐藏层，如果用多隐藏层，一般不同隐藏层的单元数相同；通常一个隐藏层的单元数越多越好；一般来说，隐藏层的单元数取为稍大于特征数量（或其一倍、两倍、三倍等）
2. 训练神经网络Training a neural network
   1. 随机初始化权重
   2. 用输入值通过前向传播计算预测值
   3. 计算代价函数
   4. 通过后向传播计算代价函数对参数的偏微分（一般来说用for循环计算每一个样本的所有激励值和误差值，再迭代） [Fig 09-18]
   5. 通过梯度检测判断后向传播是否有误，然后关闭梯度检测
   6. 通过优化算法获得最小化代价函数的参数（虽然代价函数可能是非凸non-convex的，但一般来说优化函数包括梯度下降即使得到的是局部最优值，也是一个非常小的局部最优值） [Fig 09-19]

**神经网络中梯度下降算法的直观理解（后向传播起到的是找到下降方向的作用）** [Fig 09-20]

### 自动驾驶 Autonomous Driving



## Lecture 10 机器学习应用建议



### 改进机器学习算法 Debugging a Learning Algorithm

**改进机器学习算法的方法**

1. 得到更多的训练样本
2. 尝试更少的特征集（挑选少一些防止过拟合）
3. 尝试更多的特征集（目前特征涵盖的信息不够）
4. 增加多项式特征（即x1^2、x1x2等项）
5. 减小正则化参数的值
6. 增大正则化参数的值

* 机器学习诊断法Machine Learning Diagnostic：测试机器学习是否有用，以及什么是最好的改进方法

### 假设函数评价 Evaluating a Hypothesis

* 即判断假设函数是否欠拟合或过拟合
* 变量少的时候可以通过画图观察
* 变量多的时候拆分数据集：一部分为训练集Training Set，一部分为测试集Test Set；一般按照7:3的比例；训练集的样本数量$m$，测试集的样本数量$m_{test}$；如果数据集有规律，需要随机选择 [Fig 10-01]
* 通过测试集计算出参数后，用同一代价函数计算测试集的代价函数值；线性回归直接计算即可，逻辑回归的误差（代价函数值）叫做误分类率Misclassification Error或0/1错分率0/1 Misclassification Error [Fig 10-02]

### 模型选择和训练/验证/测试集 Model Selection and Training/Validation/Test Sets

* 模型选择：确定对于某组数据最合适的多项式次数是几次、选择合适的特征、确定正则化参数的大小等
* 泛化误差Generalization Error：一个数据集训练的假设在其他所有数据集中表现的误差；一个数据集的预测误差（如训练误差）不能作为泛化误差，通常比泛化误差要小
* 如何确定最佳多项式次数：用测试误差最小确定参数，但是这样便不能用测试误差作为泛化误差 [Fig 10-03]
* 将数据集做三个划分：训练集Training Set，交叉验证集Cross Validation Set（CV）（样本数量$m_{cv}$），测试集Test Set；分配比例一般是6:2:2 [Fig 10-04]
* 三个数据集的误差均用同一代价函数表示 [Fig 10-05]
* 实际操作中，不再用测试集选择多项式的最佳次数，而是用验证集进行选择，然后再用测试集预测或估计模型和算法的泛化误差

### 偏差与方差 Bias and Variance

* 模型问题一般是偏差比较大或方差比较大，也即是欠拟合或过拟合的问题
* 高偏差High Bias是欠拟合Underfit，高方差High Variance（即不平滑）是过拟合Overfit [Fig 10-06]
* 随着多项式次数增加，训练误差减小，交叉验证误差先减小后增加；即次数过小对应了高偏差（欠拟合，训练误差和交叉验证误差都很大），次数过大对应了高方差（过拟合，交叉验证误差大，但是训练误差小） [Fig 10-07] & [Fig 10-08]

### 正则化与偏差和方差 Regularization and Bias and Variance

* 正则化参数过大，则对应曲线过于平滑，欠拟合，高偏差；正则化参数过小，对应曲线没有经过正则化，次数过高，过拟合，高方差 [Fig 10-09] & [Fig 10-10]
* 如何选择合适的lambda：定义不带正则化项的交叉验证集代价函数，在训练集中尝试从0、0.01、0.02等两倍增长的lambda参数，直至lambda等于10（准确的说10.24），分别得到不同的参数集，再用得到的参数计算交叉验证集的代价函数值，选择最小的，再通过测试集得到泛化误差 [Fig 10-11]

### 学习曲线 Learning Curves

* 学习曲线：训练误差和交叉验证误差/测试误差随训练集样本数量增加而发生的变化；模型合适时，训练误差逐渐增加（需要拟合的数据多了），交叉验证误差逐渐减小（样本数量越多，泛化性越好） [Fig 10-12]
* 高偏差时，交叉验证误差很快下降至水平，变化不会太明显，同时误差值很高；训练误差会很快上升到同样的高误差值；随着样本数量上升，二者数值会非常接近 [Fig 10-13]
* 高方差时，训练误差从很小开始增加（样本数量增加后过拟合去拟合仍然变得困难，所以会增加），样本数量大时误差仍然很小；交叉验证误差会从很高的位置下降，但始终很高；随着样本数量上升，二者之间仍有很大差距 [Fig 10-14]
* 对于高方差，持续增加数据会使交叉验证误差/测试误差下降，训练误差上升，二者会越来越接近，因此此时增加数据量是改进算法的一种方法

### 改进机器学习算法的总结

**改进机器学习算法的方法效果** [Fig 10-15]

1. 得到更多的训练样本：对高方差有效
2. 尝试更少的特征集（挑选少一些防止过拟合）：对高方差有效
3. 尝试更多的特征集（目前特征涵盖的信息不够）：对高偏差有效
4. 增加多项式特征（即x1^2、x1x2等项）：对高偏差有效
5. 减小正则化参数的值：对高偏差有效
6. 增大正则化参数的值：对高方差有效

**神经网络结构比较** [Fig 10-16]

1. 小型神经网络可能出现欠拟合的情况，但计算量很小
2. 大型神经网络可能出现过拟合的情况，同时计算量很大
3. 越大型的神经网络性能越好
4. 大型神经网络的过拟合问题可以通过正则化修正；正则化对大型神经网络的效果比对小型神经网络的效果好
5. 如何选择合适隐藏层层数：一般选择一个；选择多个时通过训练集、验证集和测试集判断



## Lecture 11 机器学习系统设计



### 改进机器学习系统

* 样本量、特征量、算法等 [Fig 11-01]

### 误差分析 Error Analysis

* 分析如何改进：从简单算法入手验证、绘制学习曲线、误差分析 [Fig 11-02]
* 误差分析：人工检查被错误分类的样本，总结错误分类的原因；核心是找出什么样本是算法最难分类的【所以建议先用简单的算法跑一跑】 [Fig 11-02] & [Fig 11-03]
* 词干提取Stemming：NLP的感念，找到语义相近词的共同点
* 通过数值验证算法改进的效果（如通过交叉验证集的误差率判断使用词干提取和不用词干提取的垃圾邮件分类算法效果哪个更好）；一定要用交叉验证集而不是测试集【为什么？】 [Fig 11-04]

### 偏斜类的误差分析 Error Analysis for Skewed Classes

* 斜偏类：相比其他类样本数量特别多或特别少的类
* 样本本身的不同类别数量差距过大（如正类比负类接近1或0），会导致测试误差不可信（如恶性肿瘤概率本身只有0.5%，测试误差有1%，则比盲目预测非恶性还要高） [Fig 11-05]
* 查准率Precision：预测为正类的样本中有多大概率是真正的正类 [Fig 11-06]
* 召回率Recall：正类的样本有大概率被正确预测
* 查准率和召回率的定义中，$y=1$通常表示出现出现数量少的类
* 查准率和召回率都是越高越好

### 查准率和召回率的权衡

* 提高逻辑回归的临界值，查准率提高，召回率降低；降低逻辑回归的临界值，召回率提高，查准率降低 [Fig 10-07]
* F1值F1 Score/F值F Score：权衡查准率和召回率的值，$F = 2\frac{PR}{P+R}$；不用平均值，因为极端情况平均值很高 [Fig 10-08]

### 机器学习的数据

* 以前的研究表明，大样本数据量足够大的情况下，所有的算法效能都有所提高，甚至样本量小时表现差的算法在样本量大的时候效果会超过其他样本量小时表现更好的算法，即算法的效果有时候依赖一些数据细节，这在下面的论点中得到了更具体的论述（即何时大样本有效，应该是特征涵盖信息足够多的时候） [Fig 10-09]
* 有足够多的特征值可以保证低方差，训练误差很小；在此基础上样本量远大于特征数量，则不易出现过拟合，低偏差，二者同时导致测试误差小，算法效果好 [Fig 10-10] & [Fig 10-11]

